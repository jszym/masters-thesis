\section{Machine Learning and the Medical Context}

Machine learning is the study of algorithms that can generalise solutions to problem-spaces without having been explicitly programmed them, but instead by ``learning'' from experiences, employing techniques from the fields of computational statistics, artificial intelligence, and mathematical optimisation.

One of its very first applications, Arthur Samuels coined the term ``machine learning'' to describe an automated Checkers-playing computer programme he had devised \citep{samuel_draughts}. The Samuels Checkers programme demonstrated that it was possible to have machines solve problems by implementing learning algorithms as opposed to programming solutions in ``minute detail'' in situations where doing so may be unreasonably onerous or even entirely infeasible.

Medical applications of machine learning can be found early in its history, with Earl Hunt's application of his Concept Learning System (CLS) for the purpose of medical diagnosis and prognosis as early as 1966 \citep{hunt1966}. Hunt recognised and stated that machine-learning techniques such as his CLS approach are particularly well-suited for analysing the often large amounts of data collected by medical tests, obviating time-consuming and expensive specialised investigations. The data generated by medical imaging is, in particular, both very rich and difficult to analyse in an efficient, reproducible manner.

Machine-learning systems for medical applications are preferably of high accuracy and transparent to physicians in its methods, such that unexpected decisions are offered with an explanation that a physician can choose to agree or disagree with \citep{med_ml_review}.

The field of machine learning has given rise to a multitude of algorithms, and many of them have been applied to various clinically relevant models of detection and prognosis. Two families of machine learning that have been particularly important to the clinical context will here be surveyed, namely instance-based and perceptron-based machine-learning algorithms.

\subsection{Instance-Based Algorithms \& their Medical Applications}

Instance-based learning (IBL) algorithms are machine-learning algorithms that compare features from previous examples to unknown inputs to determine solutions. This is in contrast to other machine-learning algorithm families that generate internal generalised models of a problem-space.

%IBL algorithms typically trade classification speed and memory complexity for training speed. That is to say, training typically requires little to no processing of features and is therefore quick, but classification often requires memory and computation limited search algorithms.

Among IBL algorithms, the $k$-nearest neighbors ($k$-NN) and support vector machines (SVMs) are notable for having been widely used for a wide gamut of medical applications.

\subsubsection{The $k$-Nearest Neighbors Algorithm}

First described by \citeauthor{fix1951} while at the US Air Force as a technical report in \citeyear{fix1951}, and later formalised by \citeauthor{hart1967}, the $k$-NN algorithm is one of the early and fundamental machine learning algorithms, and is used in countless applications today.

The $k$-NN classification algorithm begins with its training step, whereby an $n_F$-dimensional feature space is created, where $n_F$ is the number of features per trained data point, all while keeping note of what class each data point in the training feature space belongs to. Subsequent classification steps involves obtaining the features for the unknown data and searching the feature-space generated in the training step for its $k$ nearest features in terms of Euclidean distance of the features, where $k$ is an odd integer. The unknown data is then classified as belonging to the same category as the majority of the $k$ nearest features. 

Considered a ``lazy'' machine learning algorithm, $k$-NN requires defers heavy computation from the training stage, where no additional feature processing is required, to the classification stage, which make use of memory-complex search algorithms. Data structures such as $k\textrm{-dimensional}$ ($k$-d) trees, however, can reduce the memory and computational complexity of these searches \citep{otair2013}. This, in turn, results in a reduction of time-complexity; in the case of $k$-d trees, search is performed in $O(\log n)$ time on average.

The $k$-NN algorithm has long been used for the purpose of clinical diagnostics, with early studies being applied to microcalcification detection systems for mammography, classification of aggresivity of brain tumours, and diagnosis of pigmented skin lesions \citep{knn_microcalc,knn_braintumours,knn_skinlesions}. Clinical diagnostic tools based on $k$-NN classifiers continue to be studied, with innovation focused primarily on algorithm performance and feature engineering.



\subsection{Perceptron-Based Algorithms \& their Medical Applications}

%more medical imaging (imaging gives a lot of data, blahblah)
%introduce and focus on perceptron (ANN/CNN) and statistical models (kNN), with maybe a shout-out to Bayes.