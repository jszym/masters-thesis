\section{Discussion}

The PPReCOGG model described has here been shown to effectively recognise sub-regions of cell patterning in immunofluorescent confocal imagery, provided a training set that exemplifies said patterns. The PPReCOGG model has here been employed the task of identifying, within images of human breast lesions, cell patterns that are characteristic of early breast lesions. PPReCOGG classification in this task is effective and, thanks to its GPU accelerated implementation, performed in a practical time-frame.\par

The performance of the PPReCOGG model on the Brodatz texture synthetic benchmark attest to the models proficiency at texture recognition tasks between textures that are easily distinguished by human observers upon casual visual inspection (\textit{Table 3.1}). However, PPReCOGGs true utility is most clearly evinced in the human breast lesion synthetic benchmarks, whereby texture recognition was performed on the test images (\textit{Table 3.2a}) after being trained on a dataset of human lesions. In these visually challenging tasks, PPReCOGG's accuracy is equal to or greater than those observed in the visually distinct Brodatz texture benchmarks.\par 

A partial explanation for PPReCOGGs efficiency in both visually distinct and visually challenging texture recognition tasks is provided by the MDS embeddings of the underlying Gabor features of the training set for both the Brodatz and Human Breast Lesion datasets). The MDS embedding of both datasets are remarkably similar, with both classes in each case forming distinct but intersecting planes when scaled to three-dimensional space (\textit{Figure \ref{embeddings}}). The distance between the feature-spaces of each class defines the degree to which it is possible for PPReCOGG to distinguish between them. This is largely due to PPReCOGGs reliance on the $k$-nearest neighbour algorithm for the classification of features.\par

While the PPReCOGG model readily recognises textural sub-regions within clinical samples, any clinical utility of the PPReCOGG model is dependent on and currently precluded by an immature and incomplete training set. In order for the PPReCOGG model to offer meaningful interpretation and classification of early lesions, a rich dataset is required to capture the many textural manifestations of early lesions. ADH and DCIS lesions are not homogenously or universally comprised of single textures, and so a sufficiently large and comprehensive dataset is required before the PPReCOGG model can be used to identify the many faces of early breast lesions. \par

In addition to a complete training dataset, it is possible to extend the current model to recognise sub-regions according to the identity of neighbouring sub-regions; such that some sub-region identified as belonging to some texture class $A$ would only be reported as belonging to sub-type $X$ if neighbouring regions belong to some texture class $B$ but not $C$. Rule-sets for these contextual classifications can be learned through random-forest models trained on annotated images, manually according to existing pathology guidelines, or some combination of the two. \par

The underlying conventional machine-learning algorithm that is the basis of the \mbox{PPReCOGG} model does shape the nature of the conclusions that can be drawn from its output. Namely, the PPReCOGG model is a manifestation of our current understanding of the histopathology of early breast lesions. While this approach results in highly desirable and much needed quantitative and reproducible interpretation of the pathology of biopsy tissue, PPReCOGG as a consequence does not implement feature learning. This is in contrast to models based on neural network algorithms, which forego feature engineering for hidden layers which discover them independently through optimisation. Careful inspection of the hidden layers of the neural network can potentially lead to understanding of early lesion pathology interpretation previously overlooked or otherwise unknown, however such interpretation is nuanced and often provide incomplete ``snapshots'' of the internal state of the network \citep{erhan2010, zeiler2013}.\par

% stuff about how it can't learn features like deep learning

% figure describing contextual classification