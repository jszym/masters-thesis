\section{Design \& Methods}

The DeepDuct model begins with a so-called ``off-the-shelf'' ConvNet architecture; namely the VGG16 model pre-trained on the general-purpose ImageNet dataset was used as the foundation of the DeepDuct model \citep{simonyan2014,deng2009,russakovsky2015}. Transfer-learning, a method of re-training only the ultimate fully-connected layer, as well as fine-tuning, a process of making iterative adjustments on pre-trained weights via backpropagation, was used to adapt the model to the purpose of classifying breast lesions \citep{yosinski2014}. The pre-trained VGG16 model was fine-tuned on the BreakHis dataset, a dataset of approximately 8,000 images of H\&E stained human mammary biopsy sections classified according to World Health Organisation (WHO) guidelines\citep{spanhol2016, who_breast}. Abbreviations for the class names present in the BreakHis dataset are used throughout this manuscript, and within the model itself. Refer to Appendix A for a legend of these class codes. \par

The VGG16 model was implemented with Keras using TensorFlow as the back-end \citep{chollet2015, tensorflow}. A Keras/TensorFlow implementation of Grad-CAM implemented in the Keras-Vis library was used to generate attention maps from the BreakHis-trained VGG16 model \citep{raghakot}.\par

Plots created with the matplotlib and searborn libraries \citep{hunter2007, seaborn}.
